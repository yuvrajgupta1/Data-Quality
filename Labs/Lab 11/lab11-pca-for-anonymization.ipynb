{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "durable-despite",
   "metadata": {},
   "source": [
    "# Lab 11: Anonymization Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-equality",
   "metadata": {},
   "source": [
    "In this lab we will use the same Scottish traffic dataset as last week. We'll preprocess it in the same way as we did last time. But in this week's lab we'll try a different approach to anonymization, this time using PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scotland-traffic.csv', parse_dates=['count_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-trash",
   "metadata": {},
   "source": [
    "We will extract the month from the date and use that as a separate feature. We will also recode the road type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.DatetimeIndex(df['count_date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['road_type'] = df['road_type'] == 'Major'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-shame",
   "metadata": {},
   "source": [
    "We'll get rid of the records that are missing the outcome variable. And for now we'll replace all other missing values with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.all_motor_vehicles.isna()]\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-count",
   "metadata": {},
   "source": [
    "## Predicting Number of Motor Vehicles, Given Other Features (No Anonymization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-great",
   "metadata": {},
   "source": [
    "This section of the notebook is the same as last week, predicting 'all_motor_vehicles' with no data anonymization. \n",
    "\n",
    "In our first experiment, we'll try to predict the amount of motor vehicle traffic using all of the other features, with no anonymization of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year', 'hour', 'month', 'latitude', 'longitude', 'link_length_km', 'pedal_cycles', 'two_wheeled_motor_vehicles', 'buses_and_coaches', 'road_type']\n",
    "\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['all_motor_vehicles']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-attribute",
   "metadata": {},
   "source": [
    "We'll rescale all of the features so that they will all fall within a similar range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-positive",
   "metadata": {},
   "source": [
    "We'll use 2/3 of the data for training and 1/3 for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-growing",
   "metadata": {},
   "source": [
    "For now we'll use k-nearest neigbors regression. (yet another $k$ with yet another meaning)\n",
    "\n",
    "This is a very simple regression model that is often effective. Basically when we want to predict the value of the outcome variable for a test example, we find its $k$ nearest neighbours in the training set and predict the average of their values. \n",
    "\n",
    "You could also use linear regression, or a multi-layer perceptron, or a random forest model, for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-pointer",
   "metadata": {},
   "source": [
    "We're going to report an evaluation metric called the R2 score (or r-squared metric). Basically a value close to 1 is good as it means the predictive model explains much of the variance in the outcome variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_orig = r2_score(y_test, preds)\n",
    "print('R2 Score (No Anonymization):', r2_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-enterprise",
   "metadata": {},
   "source": [
    "Not bad! We can compare the actual values with our predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_test, preds)\n",
    "plt.xlabel('actual number of motor vehicles')\n",
    "plt.ylabel('predicted number of motor vehicles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-focus",
   "metadata": {},
   "source": [
    "# Predicting Number of Motor Vehicles (With PCA Anonymized Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-respect",
   "metadata": {},
   "source": [
    "Now we'll try anonymizing the data using principal components analysis (PCA), and then trying the same prediction tasks on the anonymized data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-trash",
   "metadata": {},
   "source": [
    "We'll use the same features again, but now transforming them with PCA. We'll rescale them before doing PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year', 'hour', 'month', 'latitude', 'longitude', 'link_length_km', 'pedal_cycles', 'two_wheeled_motor_vehicles', 'buses_and_coaches', 'road_type']\n",
    "\n",
    "X = df[features]\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "y = df['all_motor_vehicles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape before PCA')\n",
    "print(X.shape)\n",
    "    \n",
    "# number of PCA components to retain\n",
    "# e.g. first 5 principal components\n",
    "num_comps = 5\n",
    "    \n",
    "pca = PCA(n_components=num_comps)\n",
    "newX = pca.fit_transform(X)\n",
    "\n",
    "print('shape after PCA')\n",
    "print(newX.shape)   \n",
    "\n",
    "print('\\nhere we can see that each observation now has a score for each of the first n principal components:\\n')\n",
    "print(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newX, y, test_size=0.33, random_state=42)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "preds_anon = knn.predict(X_test)\n",
    "\n",
    "r2_anon = r2_score(y_test, preds_anon)\n",
    "print('R2 Score (w/ PCA Anonymization):', r2_anon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-jacob",
   "metadata": {},
   "source": [
    "# Lab Assignment\n",
    "\n",
    "Try the following:\n",
    "   - Try different numbers of principal components to retain. See how the prediction performance on the anonymized data changes as you change the number of components. \n",
    "   - Try at least one other regression model other than k-nearest neighbors and see how it performs on this prediction task, both on the original data and on the anonymized data. You could use linear regression, or a multi-layer perceptron, or another regression model of your choice. \n",
    "   - When preprocessing the data, we replaced all missing values with 0. Change this so that each column has its missing values replaced with the median value of the column. See if this changes the performance of the prediction models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-array",
   "metadata": {},
   "source": [
    "### Deliverables: Submit your completed notebook via Blackboard. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
