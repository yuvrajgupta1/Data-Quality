{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "durable-despite",
   "metadata": {},
   "source": [
    "# Lab 10: Anonymization Using K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-equality",
   "metadata": {},
   "source": [
    "In this lab we will use some traffic data from Scotland. Each record consists of a traffic measurement at a particular location and time. We will try to predict the total amount of motor vehicle traffic (all_motor_vehicles), given other features such as hour, time, year, location coordinates, type of road, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scotland-traffic.csv', parse_dates=['count_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-trash",
   "metadata": {},
   "source": [
    "We will extract the month from the date and use that as a separate feature. We will also recode the road type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.DatetimeIndex(df['count_date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['road_type'] = df['road_type'] == 'Major'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-shame",
   "metadata": {},
   "source": [
    "We'll get rid of the records that are missing the outcome variable. And for now we'll replace all other missing values with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.all_motor_vehicles.isna()]\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-count",
   "metadata": {},
   "source": [
    "## Predicting Number of Motor Vehicles, Given Other Features (No Anonymization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-great",
   "metadata": {},
   "source": [
    "In our first experiment, we'll try to predict the amount of motor vehicle traffic using all of the other features, with no anonymization of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year', 'hour', 'month', 'latitude', 'longitude', 'link_length_km', 'pedal_cycles', 'two_wheeled_motor_vehicles', 'buses_and_coaches', 'road_type']\n",
    "\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['all_motor_vehicles']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-attribute",
   "metadata": {},
   "source": [
    "We'll rescale all of the features so that they will all fall within a similar range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-positive",
   "metadata": {},
   "source": [
    "We'll use 2/3 of the data for training and 1/3 for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-growing",
   "metadata": {},
   "source": [
    "For now we'll use k-nearest neigbors regression. (yet another $k$ with yet another meaning)\n",
    "\n",
    "This is a very simple regression model that is often effective. Basically when we want to predict the value of the outcome variable for a test example, we find its $k$ nearest neighbours in the training set and predict the average of their values. \n",
    "\n",
    "You could also use linear regression, or a multi-layer perceptron, or a random forest model, for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-pointer",
   "metadata": {},
   "source": [
    "We're going to report an evaluation metric called the R2 score (or r-squared metric). Basically a value close to 1 is good as it means the predictive model explains much of the variance in the outcome variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_orig = r2_score(y_test, preds)\n",
    "print('R2 Score (No Anonymization):', r2_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-enterprise",
   "metadata": {},
   "source": [
    "Not bad! We can compare the actual values with our predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_test, preds)\n",
    "plt.xlabel('actual number of motor vehicles')\n",
    "plt.ylabel('predicted number of motor vehicles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-focus",
   "metadata": {},
   "source": [
    "# Predicting Number of Motor Vehicles (With Anonymized Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-respect",
   "metadata": {},
   "source": [
    "Now we'll try anonymizing the data using k-means clustering, and then trying the same prediction tasks on the anonymized data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-stockholm",
   "metadata": {},
   "source": [
    "We'll first attempt this with 20 clusters. That's a really low value for this dataset. Each cluster will end up having a large number of observations and the dataset will end up being heavily modified as a result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-bench",
   "metadata": {},
   "source": [
    "We'll add the cluster assignments to our original dataframe. Each record/observation has a cluster number now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = kmeans.labels_\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-relief",
   "metadata": {},
   "source": [
    "We'll create a new dataframe that stores the centroid vector for each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_anon = [f+'_anon' for f in features]\n",
    "\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=feas_anon)\n",
    "cluster_centers['cluster_num'] = cluster_centers.index\n",
    "print(cluster_centers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-knowing",
   "metadata": {},
   "source": [
    "Now we'll join those two dataframes, so that we have a new dataframe which contains both the original data and the anonymized data for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df.merge(cluster_centers, how='left', left_on='cluster', right_on='cluster_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-substitute",
   "metadata": {},
   "source": [
    "In our second experiment, we'll use just the anonymized features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = df_merge[feas_anon]\n",
    "new_y = df_merge['all_motor_vehicles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_X, new_y, test_size=0.33, random_state=42)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "preds_anon = knn.predict(X_test)\n",
    "\n",
    "r2_anon = r2_score(y_test, preds_anon)\n",
    "\n",
    "print('R2 Score (With Anonymization):', r2_anon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-terrain",
   "metadata": {},
   "source": [
    "Our score has taken quite a hit. That's not too surprising, given that we used a very small number of clusters, resulting in an anonymized dataset in which a lot of information was lost. In the lab assignment, you'll see if you can improve this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-jacob",
   "metadata": {},
   "source": [
    "# Lab Assignment\n",
    "\n",
    "Try the following:\n",
    "   - Try different number of clusters (e.g. both smaller and greater than what we tried) and anonymize the data using those clusterings. See how the prediction performance on the anonymized data changes as you change the number of clusters. Keep in mind that if you try a very large number of clusters, it may take several minutes to find a solution. \n",
    "   - Try at least one other regression model other than k-nearest neighbors and see how it performs on this prediction task, both on the original data and on the anonymized data. You could use linear regression, or a multi-layer perceptron, or another regression model of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-array",
   "metadata": {},
   "source": [
    "### Deliverables: Submit your completed notebook via Blackboard. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
